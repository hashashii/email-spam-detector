# train_model.py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pickle
import os

print("="*70)
print("ğŸš€ EMAIL SPAM DETECTOR - AI MODEL TRAINING")
print("="*70)

# ============================================
# STEP 1: Load Dataset
# ============================================
print("\nğŸ“‚ STEP 1: Loading dataset...")
df = pd.read_csv('spam_dataset.csv')

# Clean data
df = df.dropna()  # null values à¶‰à·€à¶­à·Š à¶šà¶»à¶±à·€à·
df['label'] = df['label'].map({'ham': 0, 'spam': 1})  # Convert to numbers

print(f"âœ… Dataset loaded successfully!")
print(f"   ğŸ“§ Total Emails: {len(df)}")
print(f"   âœ… Safe Emails: {len(df[df['label']==0])}")
print(f"   âš ï¸ Spam Emails: {len(df[df['label']==1])}")

# ============================================
# STEP 2: Prepare Data
# ============================================
print("\nğŸ”§ STEP 2: Preparing data for training...")
X = df['text']
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"âœ… Data split complete!")
print(f"   ğŸ“š Training set: {len(X_train)} emails ({len(X_train)/len(df)*100:.1f}%)")
print(f"   ğŸ§ª Test set: {len(X_test)} emails ({len(X_test)/len(df)*100:.1f}%)")

# ============================================
# STEP 3: Text Vectorization
# ============================================
print("\nğŸ”¢ STEP 3: Converting text to numbers (Vectorization)...")
vectorizer = TfidfVectorizer(
    max_features=3000,        # à·€à·à¶¯à¶œà¶­à·Šà¶¸ à·€à¶ à¶± 3000 à·€à·’à¶­à¶»à¶šà·Š
    stop_words='english',     # "the", "is" à·€à¶œà·š à¶…à¶±à·€à·à·Šâ€à¶º à·€à¶ à¶± remove
    ngram_range=(1, 2),       # single words + word pairs
    min_df=2                  # à¶…à·€à¶¸ à·€à·à¶ºà·™à¶±à·Š 2 emails à·€à¶½à·€à¶­à·Š à¶­à·’à¶ºà·™à¶± à·€à¶ à¶±
)

X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

print(f"âœ… Vectorization complete!")
print(f"   ğŸ“Š Feature count: {X_train_vec.shape[1]} unique features")
print(f"   ğŸ’¾ Training data shape: {X_train_vec.shape}")

# ============================================
# STEP 4: Train AI Model
# ============================================
print("\nğŸ§  STEP 4: Training AI model...")
print("   â³ Please wait...")

model = MultinomialNB(alpha=0.1)
model.fit(X_train_vec, y_train)

print("âœ… Training complete!")

# ============================================
# STEP 5: Evaluate Model Performance
# ============================================
print("\nğŸ“Š STEP 5: Evaluating model performance...")
print("   â³ Testing on unseen data...")

y_pred = model.predict(X_test_vec)
accuracy = accuracy_score(y_test, y_pred)

print(f"\n{'='*70}")
print(f"ğŸ¯ MODEL ACCURACY: {accuracy * 100:.2f}%")
print(f"{'='*70}")

print("\nğŸ“ˆ Detailed Classification Report:")
print("-"*70)
print(classification_report(y_test, y_pred, target_names=['Safe Email', 'Spam Email']))

print("\nğŸ“‰ Confusion Matrix:")
print("-"*70)
cm = confusion_matrix(y_test, y_pred)
print(f"âœ… True Negatives (Correctly identified Safe):  {cm[0][0]}")
print(f"âŒ False Positives (Safe marked as Spam):       {cm[0][1]}")
print(f"âŒ False Negatives (Spam marked as Safe):       {cm[1][0]}")
print(f"âœ… True Positives (Correctly identified Spam):  {cm[1][1]}")

# ============================================
# STEP 6: Save Model
# ============================================
print(f"\nğŸ’¾ STEP 6: Saving trained model...")

# Create models directory
os.makedirs('models', exist_ok=True)

with open('models/spam_model.pkl', 'wb') as f:
    pickle.dump(model, f)

with open('models/vectorizer.pkl', 'wb') as f:
    pickle.dump(vectorizer, f)

print("âœ… Model saved successfully!")
print(f"   ğŸ“ Model file: models/spam_model.pkl")
print(f"   ğŸ“ Vectorizer file: models/vectorizer.pkl")

# ============================================
# STEP 7: Live Testing
# ============================================
print(f"\n{'='*70}")
print("ğŸ§ª STEP 7: LIVE TESTING WITH SAMPLE EMAILS")
print(f"{'='*70}\n")

test_samples = [
    "Congratulations! You've won a $1000 gift card. Click here now!",
    "Hi, can we schedule our meeting for tomorrow at 3 PM?",
    "URGENT: Your account will be closed. Verify your identity now!",
    "The project report has been submitted. Please review when you can.",
    "Get rich quick! Make $5000 per week working from home!",
    "Thanks for your email. I'll get back to you soon.",
    "FREE FREE FREE! Win an iPhone 15 Pro Max today!!!",
    "Meeting reminder: Team standup at 10 AM tomorrow"
]

for i, email in enumerate(test_samples, 1):
    email_vec = vectorizer.transform([email])
    prediction = model.predict(email_vec)[0]
    probability = model.predict_proba(email_vec)[0]
    
    if prediction == 1:
        result = "ğŸš¨ SPAM"
        confidence = probability[1] * 100
        emoji = "âš ï¸"
    else:
        result = "âœ… SAFE"
        confidence = probability[0] * 100
        emoji = "âœ…"
    
    print(f"{i}. {emoji} Email: {email[:55]}...")
    print(f"   Result: {result} | Confidence: {confidence:.1f}%")
    print("-"*70)

print(f"\n{'='*70}")
print("âœ… TRAINING COMPLETE! MODEL IS READY TO USE!")
print(f"{'='*70}\n")

print("ğŸ“Œ Next Steps:")
print("   1. Run 'python test_email.py' to test with your own emails")
print("   2. Run 'python app.py' to start the web interface")
print("\n")